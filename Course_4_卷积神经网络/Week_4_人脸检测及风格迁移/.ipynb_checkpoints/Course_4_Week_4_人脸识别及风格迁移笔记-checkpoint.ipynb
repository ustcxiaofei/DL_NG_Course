{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**主要内容**\n",
    "- 人脸识别、one-shot学习、\n",
    "- Siamese网络、Triplet损失、\n",
    "- 风格迁移、内容损失、风格损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸识别\n",
    "## 人脸验证与人脸识别\n",
    "**人脸验证**\n",
    "- Input：图片、名字/ID；\n",
    "- Output：输入的图片是否是对应的人。\n",
    "- 1 to 1 问题。\n",
    "\n",
    "**人脸识别**\n",
    "- 拥有一个具有K个人的数据库；\n",
    "- 输入一副人脸图片；\n",
    "- 如果图片是任意这K个人中的一位，则输出对应人的ID。\n",
    "\n",
    "人脸识别问题对于人脸验证问题来说，具有更高的难度。如对于一个验证系统来说，如果我们拥有99%的精确度，那么这个验证系统已经具有了很高的精度；但是假设在另外一个识别系统中，如果我们把这个验证系统应用在具有K个人的识别系统中，那么系统犯错误的机会就变成了K倍。所以如果我们想在识别系统中得到更高的精度，那么就需要得到一个具有更高精度的验证系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-shot learning\n",
    "对于大多数的人脸识别系统都存在的一个问题就是**one shot learning**。\n",
    "\n",
    "**什么是one shot learning：**\n",
    "\n",
    "对于一个人脸识别系统，我们需要仅仅通过先前的一张人脸的图片或者说一个人脸的样例，就能够实现该人的识别，那么这样的问题就是one shot 问题。对于存在于数据库中的人脸图片，系统能够识别到对应的人；而不在数据库中的人脸图片，则系统给出无法通过识别的结果。\n",
    "![oneshot](./Image/oneshot.png)\n",
    "对于one shot learning 问题，因为只有单个样本，是不足以训练一个稳健的卷积神经网络来进行不同人的识别过程。而且，在有新的样本成员加入的时候，往往还需要对网络进行重新训练。所以我们不能以传统的方法来实现识别系统。\n",
    "\n",
    "**similarity函数**\n",
    "\n",
    "为了能够让人脸识别系统实现一次学习，需要让神经网络学习 Similarity 函数：\n",
    "\n",
    "- d(img1, img2)：两幅图片之间的差异度\n",
    "- 输入：两幅图片\n",
    "- 输出：两者之间的差异度\n",
    "   - 如果 d(img1,img2)⩽τ，则输出“same”; \n",
    "   - 如果d(img1,img2)>τ，则输出“different”.\n",
    "对于人脸识别系统，通过将输入的人脸图片与数据库中所拥有的图片成对输入Similarity函数，两两对比，则可解决one shot problem。如果有新的人加入团队，则只需将其图片添加至数据库即可。\n",
    "\n",
    "**siamense网络**\n",
    "\n",
    "利用Siamese 网络来实现 Similarity 函数。\n",
    "\n",
    "**构建网络**\n",
    "![siamense](./Image/siamense.png)\n",
    "\n",
    "对于一个卷积神经网络结构，我们去掉最后的softmax层，将图片样本1输入网络，最后由网络输出一个N维的向量（图中实例以128表示），这N维向量则代表输入图片样本1的编码。将不同人的图片样本输入相同参数的网络结构，得到各自相应的图片编码。\n",
    "\n",
    "**similarity函数实现**\n",
    "\n",
    "将Similarity 函数表示成两幅图片编码之差的范数：\n",
    "$$d(x1, x2) = ||f(x1)-f(x2)||_{2}^{2}$$\n",
    "\n",
    "那么也就是说：\n",
    "\n",
    "- 我们的神经网络的参数定义了图片的编码；\n",
    "- 学习网络的参数，使我们得到好的Similarity 函数(**学习参数的目的**)： \n",
    "   - 如果x1，x2是同一个人的图片，那么得到的||f(x1)−f(x2)||2很小；\n",
    "   - 如果x1，x2不是同一个人的图片，那么得到的||f(x1)−f(x2)||很大。\n",
    "\n",
    "**Triplet损失**\n",
    "\n",
    "如何通过学习神经网络的参数，得到优质的人脸图片的编码？方法之一就是定义 Triplet 损失函数，并在其之上运用梯度下降。\n",
    "\n",
    "**学习目标：**\n",
    "\n",
    "为了使用Triplet 损失函数，我们需要比较成对的图像（三元组术语）：\n",
    "![triplet](./Image/triplet.png)\n",
    "\n",
    "- Anchor （A）： 目标图片；\n",
    "- Positive（P）：与Anchor 属于同一个人的图片；\n",
    "- Negative（N）：与Anchor不属于同一个人的图片。\n",
    "\n",
    "对于Anchor 和 Positive，我们希望二者编码的差异小一些；对于Anchor 和Negative，我们希望他们编码的差异大一些。所以我们的目标以编码差的范数来表示为：\n",
    "$$d(A,P)=||f(A) - f(P)||^{2} \\leqslant ||f(A) - f(N)||^{2} = d(A,N)$$\n",
    "\n",
    "上面的公式存在一个问题就是，当f(A)=f(P)=f(N)=0时，也就是神经网络学习到的函数总是输出0时，或者f(A)=f(P)=f(N)时，也满足上面的公式，但却不是我们想要的目标结果。所以为了防止出现这种情况，我们对上式进行修改，使得两者差要小于一个较小的负数：\n",
    "$$||f(A) - f(P)||^{2}  - ||f(A) - f(N)||^{2}   + \\alpha \\leqslant 0$$\n",
    "不同 **margin** (a) 值的设置对模型学习具有不同的效果，margin 的作用就是拉大了 Anchor与Positive 图片对 和 Anchor与Negative 图片对之间的差距。\n",
    "\n",
    "**Triplet 损失函数**：\n",
    "\n",
    "Triplet 损失函数的定义基于三张图片：Anchor、Positive、Negative。\n",
    "$$L(A,P,N) = \\max (||f(A) - f(P)||^{2} - ||f(A) - f(N)||^{2} + \\alpha,  \\ 0)$$\n",
    "整个网络的代价函数：\n",
    "$$J = \\sum\\limits_{i=1}^{m}L(A^{(i)},P^{(i)},N^{(i)})$$\n",
    "假设我们有一个10000张片的训练集，里面是1000个不同的人的照片样本。我们需要做的就是从这10000张训练集中抽取图片生成（A,P,N）的三元组，来训练我们的学习算法，并在Triplet 损失函数上进行梯度下降。\n",
    "\n",
    "注意：为了训练我们的网络，我们必须拥有Anchor和Positive对，所以这里我们必须有每个人的多张照片，而不能仅仅是一张照片，否则无法训练网络。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**三元组的选择**\n",
    "\n",
    "为了更好地训练网络，我们需要选择那些训练有“难度”的三元组，也就是选择的三元组满足：\n",
    "$d(A,P)  \\approx d(A,N)$\n",
    "\n",
    "- 算法将会努力使得d(A,N)变大，或者使得d(A,N)+α变小，从而使两者之间至少有一个α的间隔；\n",
    "- 增加学习算法的计算效率，避免那些太简单的三元组。\n",
    "最终通过训练，我们学习到的参数，会使得对于同一个人的图片，编码的距离很小；对不同人的图片，编码的距离就很大。\n",
    "\n",
    "对于大型的人脸识别系统，常常具有上百万甚至上亿的训练数据集，我们并不容易得到。所以对于该领域，我们常常是下载别人在网上上传的预训练模型，而不是从头开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 脸部验证与二分类\n",
    "除了利用 Triplet 损失函数来学习人脸识别卷积网络参数的方法外，还有其他的方式。我们可以将人脸识别问题利用Siamese网络当成一个二分类问题，同样可以实现参数的学习。\n",
    "\n",
    "**Siamese 二分类改进**：\n",
    "\n",
    "对两张图片应用Siamese 网络，计算得到两张图片的N维编码，然后将两个编码输入到一个logistic regression 单元中，然后进行预测。如果是相同的人，那么输出是1；如果是不同的人，输出是0。那么这里我们就将人脸识别的问题，转化为一个二分类问题。\n",
    "\n",
    "![sig](./Image/sig.png)\n",
    "\n",
    "对于最后的sigmoid函数，我们可以进行如下计算：$$\\hat y = \\sigma(\\sum\\limits_{k=1}^{N} w_{i}|f(x^{(i)})_{k}  - f(x^{(j)})_{k} | + b)$$\n",
    "\n",
    "在实际的人脸验证系统中，我们可以对数据库的人脸图片进行预计算，存储卷积网络得到的编码。当有图片进行识别时，运用卷积网络计算新图片的编码，与预计算保存好的编码输入到逻辑回归单元中进行预测。这样可以提高我们系统预测的效率，节省计算时间。\n",
    "\n",
    "总结： \n",
    "利用Siamese 网络，我们可以将人脸验证当作一个监督学习，创建成对的训练集和是否同一个人的输出标签。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经风格迁移\n",
    "\n",
    "## 可视化网络\n",
    "\n",
    "### 如何可视化\n",
    "假设我们训练了一个卷积神经网络，我们希望看到不同层的隐藏单元的计算结果。依次对各个层进行如下操作：\n",
    "- 在当前层挑选一个隐藏单元；\n",
    "- 遍历训练集，找到**最大化地激活了该运算单元的图片或者图片块**；\n",
    "- 对该层的其他运算单元执行操作。\n",
    "对于在第一层的隐藏单元中，其只能看到卷积网络的小部分内容，也就是最后我们找到的那些最大化激活第一层隐层单元的是一些小的图片块。我们可以理解为第一层的神经单元通常会寻找一些简单的特征，如边缘或者颜色阴影等。\n",
    "\n",
    "### 各层网络可视化：\n",
    "对于卷积网络的各层单元，随着网络深度的增加，隐藏层计算单元随着层数的增加，从简单的事物逐渐到更加复杂的事物。\n",
    "![show](./Image/show.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经风格迁移的代价函数\n",
    "为了实现神经风格迁移，我们需要为生成的图片定义一个代价函数。\n",
    "\n",
    "对于神经风格迁移，我们的目标是由内容图片C和风格图片S，生成最终的风格迁移图片G：\n",
    "![trans](./Image/trans.png)\n",
    "\n",
    "所以为了实现神经风格迁移，我们需要定义关于G的代价函数J，以用来评判生成图片的好坏：\n",
    "\n",
    "$$J(G) = \\alpha J_{content}(C, G) + \\beta J_{style}(S,G)$$\n",
    "\n",
    "其中：\n",
    "- Jcontent(C,G)代表生成图片G的内容和内容图片C的内容的相似度；\n",
    "- Jstyle(S,G) 代表生成图片G的内容和风格图片S的内容的相似度；\n",
    "- α、β两个超参数用来表示以上两者之间的权重。\n",
    "**执行过程**\n",
    "\n",
    "- 随机初始化生成图片G，如大小为100×100×3；\n",
    "- 使用梯度下降算法最小化上面定义的代价函数 J(G)\n",
    "\n",
    "对于上图的内容图片C和风格图片S，通过梯度下降算法一次次训练，我们可以由初始的噪声图片得到最终的风格迁移图片G。\n",
    "\n",
    "### 内容代价函数\n",
    "\n",
    "- 假设我们使用隐藏层l来计算内容代价。（如果选择的l 太小，那么代价函数就会使得我们的生成图片G在像素上非常接近内容图片；然而用很深的网络，那么生成图片G中就会产生与内容图片中所拥有的物体。所以对于ll 一般选在网络的中间层，既不深也不浅）；\n",
    "- 使用一个预训练的卷积网络。（如，VGG或其他）；\n",
    "- 令$a^{[l](C)}$和$a^{[l](G)}$分别代表内容图片C和生成图片G的l 层的激活值；\n",
    "- 如果$a^{[l](C)}$和$a^{[l](G)}$相似，那么两张图片就有相似的内容；\n",
    "\n",
    "定义内容代价函数如下：\n",
    "$$J_{content}(C, G) = \\dfrac{1}{2}||a^{[l](C)} - a^{[l](G)} ||^{2}$$\n",
    "在对代价函数运行梯度下降算法时，会激励这里的内容代价函数，努力使得生成图片G隐含层l 的激活值和内容图片C隐含层l 的激活值相似。\n",
    "\n",
    "### 风格代价函数\n",
    "\n",
    "**style的意义**\n",
    "\n",
    "对于一个卷积网络中，我们选择网络的中间层l， 定义“Style”表示 l 层的各个通道激活项之间的相关性。\n",
    "![style](./Image/style.png)\n",
    "\n",
    "**相关性大小的度量**\n",
    "\n",
    "![style2](./Image/style2.png)\n",
    "\n",
    "上面是我们选出的ll层的激活项，对于不同的通道值，代表不同的神经元所学习到的特征，这里假如红色的通道可以找到图片中含有垂直纹理特征的区域，黄色通道可以找出橙色的区域。\n",
    "\n",
    "而相关性大小的含义就是，如假设中，图片出现垂直纹理特征的区域显示橙色可能的大小。\n",
    "\n",
    "我们将相关系数应用到风格图片S和生成图片G的对应通道上，就可以度量风格图片和生成图片的相似度。\n",
    "\n",
    "**Style 矩阵：**\n",
    "\n",
    "- 令$a^{[l]}_{i,j,k}$表示在（i,j,k）位置的激活值，其中i、j、k分别代表激活值的高、宽、通道\n",
    "- $G^{[l]}$ 是一个$n^l_c×n^l_c$大小的矩阵： \n",
    "$$G^{[l](S)}_{kk'} = \\sum\\limits_{i=1}^{n_{h}^{[l]}}\\sum\\limits_{j=1}^{n_{w}^{[l]}}a^{[l](S)}_{i,j,k}a^{[l](S)}_{i,j,k'}$$\n",
    "$$G^{[l](G)}_{kk'} = \\sum\\limits_{i=1}^{n_{h}^{[l]}}\\sum\\limits_{j=1}^{n_{w}^{[l]}}a^{[l](G)}_{i,j,k}a^{[l](G)}_{i,j,k'}$$\n",
    "\n",
    "上面的矩阵在线性代数中又称为Gram 矩阵，这里称为风格矩阵\n",
    "\n",
    "**风格代价函数**\n",
    "\n",
    "$$J^{[l]}_{style}(S, G) = \\dfrac{1}{2n^{[l]}_{h}n^{[l]}_{w}n^{[l]}_{c}}||G^{[l](S)} - G^{[l](G)} ||^{2}_{F} = \\dfrac{1}{2n^{[l]}_{h}n^{[l]}_{w}n^{[l]}_{c}}\\sum_{k}\\sum_{k'}(G^{[l](S)}_{kk'} - G^{[l](G)}_{kk'})^{2}$$\n",
    "\n",
    "如果对各层都使用风格代价函数，那么会让结果变得更好：\n",
    "\n",
    "$$J_{style}(S,G) = \\sum_{l}\\lambda^{[l]}J_{style}^{[l]}(S,G)$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
